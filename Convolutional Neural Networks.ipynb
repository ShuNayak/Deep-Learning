{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen that using multilayer perceptron to solve a wide variety of problems. You can do much more by arranging complicated neural networks together and solving more complicated problems.\n",
    "\n",
    "ususally CNN is mostly used for image analysis. Their whole point is to find points in data that might not be what we expected to be. It is feature location invariant, so if we want to find a patten in the data and donot know where it is CNN can find it out for us. For example: if there is a stop sign in an image it could be anywhere and a CNN can find it for you. Not just for image analysis, CNN can be used for any sort of problem where we dont know where the feature is located in the data.\n",
    "CNN is feature location invariant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired from the biology of the visual cortex, it takes idea from how brain processes images from retina, this is immersive learning. How the eye works is individual group of neurons service a specific part of vision, we call these local receptive fields - LRF is a group of neurons that only response to a aprt of what your eyes see. These areas overlap with each other to cover the entire visual field called convolutions.\n",
    "Convolutions is a way of saying breaking up the problem into chunks and process it and the higher layers shall work on solving the rest of the problem.\n",
    "\n",
    "For example:\n",
    "1. some receptive fields identigy horizontal lines, lines at different angles etc\n",
    "2. These would feed into a layer that identifies shapes\n",
    "3. Wich might feed into a layer that identifies objects\n",
    "For colored images, there will be extra layers for red, blue , green"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does a human brain know we are looking at stop sign:\n",
    "1. Individual local receptive fields scan the image and are responsible for parts of image we see. The LRF overlap with each other and scan the image looking for edges. Human brain is sensitive to contrast and edges it sees in the world. That is why letters on this slide catch attention. So at the very low level we are picking up the edges of the stop sign and the edges of the letters on the stop sign.\n",
    "2. Those edges in turn get picked up by a higher level convolution that identifies the stop sign's shape and letters too.\n",
    "3. This shape gets matched with whatever classification is in the brain for a stop sign, so this shape is matched against whatever is the pattern for the stop sign we have  and also using strong red signals coming from red layers .\n",
    "4. That information keeps getting processed until the foot hits brake.\n",
    "This is CNN.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we build a CNN using Keras:\n",
    "1. Source data must be of appropriate dimensions, i.e width, length and color channels.\n",
    "2. conv2D layer does the actual convolution on a 2D image. We have conv 1D and 3D that may been even used on text data , need not necessarily be images.\n",
    "3. MaxPooling2D can be used to reduce the 2D data down to a layer, like shrink the image.Processing CNN is very compute intensive, if we have more data than we need we can use maxPooling2D to reduce dwn to data we may need.\n",
    "4. Flatten layers will convert the 2D lyer to 1D layer for passing into a flat hidden layer of neurons.\n",
    "\n",
    "5. The typical usage will be:\n",
    "conv2D -> MaxPooling2D -> Dropout -> Flatten -> Dense -> Dropout -> Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN are compute intensive, lot of hyperparameters we can adjust on CNNs such as kernel sizes, many layers with different number of units, amount of pooling in addition to usual stuff like number of layers and choice of optimizers.\n",
    "\n",
    "Specialized CNN network architectures(defines soecific arrangements of layers, padding, hyperparameters):\n",
    "1. LeNet-5: good for handwriting recognition\n",
    "2. ALexNet : Image classificiation , deeper than LeNet\n",
    "3. GoogleNet : Even deeper, introduces inception modules ( group of convolution layers)\n",
    "4. ResNet(residual Network):maintains performance visa skip connection, special connections between layers of perceptrons to further accelerate things.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
