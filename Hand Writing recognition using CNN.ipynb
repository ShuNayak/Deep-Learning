{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels),(test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#since CNN can process 2D data, we will not convert this to 1D data\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# we need to shape the data differently than before. Since we are treating the data as a 2D image of 28X28 pixels we can shape it as 1*28*28 or 28*28*1 \n",
    "#here 1 being the greyscale, if it was color it would have been 3 (Red, Green, Blue)\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    train = train_images.reshape(train_images.shape[0],1,28,28)\n",
    "    test = test_images.reshape(test_images.shape[0],1,28,28)\n",
    "    input_shape = (1,28,28)\n",
    "else:\n",
    "    train = train_images.reshape(train_images.shape[0],28,28,1)\n",
    "    test = test_images.reshape(test_images.shape[0],28,28,1)\n",
    "    input_shape = (28,28,1)\n",
    "\n",
    "train = train.astype('float32')\n",
    "test = test.astype('float32')\n",
    "train /= 255\n",
    "test /= 255\n",
    "print(input_shape)\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the label data into one hot format\n",
    "trainL =  tensorflow.keras.utils.to_categorical(train_labels,10)\n",
    "testL = tensorflow.keras.utils.to_categorical(test_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#printing out a random trainign sample\n",
    "import matplotlib.pyplot as plt\n",
    "def display_sample(num):\n",
    "    print(trainL[num]) #one hot array format\n",
    "    label = trainL[num].argmax(axis=0)\n",
    "    image = train[num].reshape(28,28)\n",
    "    plt.title('sample %d, Label %d'%(num, label))\n",
    "    plt.imshow(image, cmap=plt.get_cmap('gray_r'))\n",
    "    plt.show()\n",
    "\n",
    "display_sample(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up a sequential model and  conv2D layer\n",
    "model = Sequential()\n",
    "#now we steup a CNN, it takes 32 windows each of size 3X3 , followed by second convolution with 64 windows each of size 3X3\n",
    "model.add(Conv2D(32, kernel_size=(3,3),activation = 'relu', input_shape=input_shape))\n",
    "#64 3X3 kernels\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "#reduce by maxpooling, shrinking data to something more manageable; pool size can be different from the kernel size\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#dropout to avoid overfitting\n",
    "model.add(Dropout(0.25))\n",
    "#flatten the results into one D to pass into the final layers\n",
    "model.add(Flatten())\n",
    "### now it is just like any multilayer perceptron where we feed the flat layer\n",
    "model.add(Dense(128, activation='relu'))\n",
    "#another dropout\n",
    "model.add(Dropout(0.4))\n",
    "#Final categorization from 0.9 with softmax\n",
    "model.add(Dense(10,activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_input to have shape (28, 28, 1) but got array with shape (1, 28, 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-3aff758bba57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#WARNING !!!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# this can take hours to run and your computer's CPU may max out\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtestL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m     x, y, sample_weights = standardize(\n\u001b[1;32m--> 646\u001b[1;33m         x, y, sample_weight=sample_weights)\n\u001b[0m\u001b[0;32m    647\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0madapter_cls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2383\u001b[1;33m         batch_size=batch_size)\n\u001b[0m\u001b[0;32m   2384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2408\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2409\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2410\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2412\u001b[0m     \u001b[1;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    580\u001b[0m                              \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 582\u001b[1;33m                              str(data_shape))\n\u001b[0m\u001b[0;32m    583\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected conv2d_input to have shape (28, 28, 1) but got array with shape (1, 28, 28)"
     ]
    }
   ],
   "source": [
    "#WARNING !!!\n",
    "# this can take hours to run and your computer's CPU may max out\n",
    "history = model.fit(train, trainL, batch_size=32, epochs=10, verbose=2, validation_data =(test,testL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(test,testL,verbose=0)\n",
    "print('Test loss:'%score[0])\n",
    "print('Test accuracy',%score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
